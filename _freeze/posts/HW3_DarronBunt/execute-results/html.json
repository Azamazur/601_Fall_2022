{
  "hash": "e55124933e8c2ac09ec0eede00544586",
  "result": {
    "markdown": "---\ntitle: \"HW3 - Darron Bunt\"\ndescription: \"Exploratory Data Analysis of Twitter Posts Made by Flagship US Colleges\"\nauthor: \"Darron Bunt\"\ndate: \"2022-12-18\"\ncategories:\n  - hw3\n  - darron_bunt\noutput: distill::distill_article\n---\n\n\n## Loading Packages into R Environment\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(stringr)\nlibrary(tm)\nlibrary(wordcloud)\n\noptions(dplyr.summarise.inform = FALSE)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\nThe emphasis in this homework is on exploratory data analysis using both graphics and statistics. You should build on your prior homework - incorporating any feedback and adjusting the code and text as needed. These homeworks are intended to be cumulative. \n\n## Loading the Dataset\n\n::: {.cell}\n\n```{.r .cell-code}\n#import data\nFlagshipTwitter <- read_csv(\"posts/_data/FlagshipTwitterUpdated.csv\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: 'posts/_data/FlagshipTwitterUpdated.csv' does not exist in current working directory ('C:/Users/Darron Bunt/OneDrive - Ascendium Education Group, Inc/Desktop/601_Fall_2022/posts').\n```\n:::\n:::\n\n\n## Descriptive Statistics - What is being produced by each college's account?\n\nThe first question that I want to answer is how frequently flagship college Twitter accounts are posting, and what type of post those posts are. Accordingly, I'm going to explore data related to the overall number of posts, and then break this down further into four post types: original posts, retweets, quote tweets, and replies.\n\n### Number of posts made by each college in the month of November\n\nFirst, I'm going to look at how many posts each college made overall during the month of November. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#remove rows where the Page Type isn't twitter\nFlagshipTwitter2 <- subset(FlagshipTwitter, PageType =='twitter')\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in subset(FlagshipTwitter, PageType == \"twitter\"): object 'FlagshipTwitter' not found\n```\n:::\n\n```{.r .cell-code}\n#rename the columns I intend to use for analysis\nFlagshipTwitter3 <- rename(FlagshipTwitter2, c(Tweet = 'Full Text', MentionedAuthors = 'Mentioned Authors', TWFollowers = 'Twitter Followers', TWReply = 'Twitter Reply Count', TWRetweets = 'Twitter Retweets', TWLikes = 'Twitter Likes', Reach = 'Reach (new)', EngType = 'Engagement Type', URL = Url))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in rename(FlagshipTwitter2, c(Tweet = \"Full Text\", MentionedAuthors = \"Mentioned Authors\", : object 'FlagshipTwitter2' not found\n```\n:::\n\n```{.r .cell-code}\n#put columns I plan to use first \nFlagshipTwitterUse <- select(FlagshipTwitter3, Author, Date, Impressions, Reach, TWLikes, TWRetweets, TWReply, EngType, Sentiment, Hashtags, MentionedAuthors, Tweet, TWFollowers, URL, everything())\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(FlagshipTwitter3, Author, Date, Impressions, Reach, TWLikes, : object 'FlagshipTwitter3' not found\n```\n:::\n\n```{.r .cell-code}\n#separate dates into respective date and time column\nTwitterUse2 <- separate(FlagshipTwitterUse, Date, into = c(\"Date\", \"Time\"), sep = \" \")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in separate(FlagshipTwitterUse, Date, into = c(\"Date\", \"Time\"), : object 'FlagshipTwitterUse' not found\n```\n:::\n\n```{.r .cell-code}\nTwitterUse2$Date <- parse_date(TwitterUse2$Date, format = \"%m/%d/%Y\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in stopifnot(is.character(x)): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\nTwitterUse2$Time <- parse_time(TwitterUse2$Time, format = \"%H:%M\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in stopifnot(is.character(x)): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\n#count posts made by each college\nby_college <- TwitterUse2 %>%\ncount(Author) %>%\n  rename(\"Total_Posts\" = \"n\") %>%\n  mutate(Total_PostsPerc = (Total_Posts/sum(Total_Posts)*100)) %>%\n  arrange(desc(Total_PostsPerc))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in count(., Author): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\nby_college\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'by_college' not found\n```\n:::\n:::\n\nWhat we see right off the bat is that post volume varies significantly depending on the flagship college in question - from 337 (Rutgers) to only two (University of South Dakota). \n\nI'm curious about the summary statistics for post volume overall, as this should provide us with greater insight into how the numbers vary across the 50 colleges.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#summary statistics for Posts by College\nsummary(by_college)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(by_college): object 'by_college' not found\n```\n:::\n:::\n\nIn addition to the difference between the minimum number of posts (two) and the maximum (337), there is also a relatively large difference in the median (93), the mean (113), and the IQR (105). \n\nThis leads me to believe that there different posting strategies are being implemented at these different schools. \n\n### Number of OG posts, retweets, quote tweet, and comments by each college\n\nTo further contextualize this information, I now want to break down of each account's post volume by the type of post that they were - either original posts, quote tweets, retweets, or comments/replies. This will help us look into not just who posts the most, but what types of posts they are making (and whether different schools are employing strategies that lean more heavily into particular types of posts). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#number of OG posts, retweets, comments made by each college\nTwitterUse2 <- TwitterUse2 %>%\n  replace_na(list(EngType = \"OG\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in replace_na(., list(EngType = \"OG\")): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\npost_type_by_college <- TwitterUse2 %>%\ngroup_by(Author, EngType) %>%\n  summarize(Count=n()) %>%\n  pivot_wider(names_from = EngType, values_from = Count)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in group_by(., Author, EngType): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\npost_types_by_college <-  merge(by_college, post_type_by_college, by=\"Author\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in merge(by_college, post_type_by_college, by = \"Author\"): object 'by_college' not found\n```\n:::\n\n```{.r .cell-code}\npost_types_by_college\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'post_types_by_college' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npost_prop_college <- post_types_by_college %>%\n  mutate(OGProp = OG/Total_Posts*100) %>%\nmutate(QuoteProp = QUOTE/Total_Posts*100) %>%\nmutate(ReplyProp = REPLY/Total_Posts*100) %>%\nmutate(RetweetProp = RETWEET/Total_Posts*100) %>%\n  select(Author, OGProp, QuoteProp, RetweetProp, ReplyProp)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., OGProp = OG/Total_Posts * 100): object 'post_types_by_college' not found\n```\n:::\n\n```{.r .cell-code}\npost_prop_college\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'post_prop_college' not found\n```\n:::\n:::\n\nI can also pull the summary statistics for each type of post. This will help to further contextualize the data regarding the types of posts made by each college. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#number of OG posts, retweets, comments made by each college\npost_type_by_college <- TwitterUse2 %>%\n  replace_na(list(EngType = \"OG\")) %>%\ngroup_by(Author, EngType) %>%\n  summarize(Count=n()) %>%\n  pivot_wider(names_from = EngType, values_from = Count)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in replace_na(., list(EngType = \"OG\")): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\npost_types_by_college <-  merge(by_college, post_type_by_college, by=\"Author\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in merge(by_college, post_type_by_college, by = \"Author\"): object 'by_college' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#summary statistics for post type by college\nsummary(post_types_by_college)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(post_types_by_college): object 'post_types_by_college' not found\n```\n:::\n:::\n\n\nInterestingly, retweets are the most common type of post, averaging 60 per author. The IQR for retweets (69) provides an idea of the level of variability in the post volume of this type by college. The number of original posts by college is more consistent, with a mean of 47 and an IQR of 37. Quote tweets are the least utilized type of posts (5.6), while replies are also relatively infrequent (8.3)\n\n### Most common day of the week to post\n\nI want to do two things at this step: ensure that I have the day of the week each post was made as a column of data, and then to use that data to break down the number of posts that were made on each day of the week.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#number of posts made on each day of the week\nTwitterUse2$Weekday <- weekdays(TwitterUse2$Date)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in weekdays(TwitterUse2$Date): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\nday_of_week <- TwitterUse2 %>%\n  count(Weekday, sort = TRUE,\n        ) %>%\n  rename(\"WD_Posts\" = \"n\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in count(., Weekday, sort = TRUE, ): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\nday_of_week\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'day_of_week' not found\n```\n:::\n:::\n\nThe most common day of the week to post is Tuesday, with Wednesday close behind. Posts on Fridays and Mondays were next most common, with Thursdays were not far behind. Weekends had the fewest posts.\n\n### Most common time of day to post\n\nThe time of day that posts are made is also a variable worth considering. I don't, however, want to look at post time down to the second; instead, I want to break the day up into four equal time periods: overnight (00:00:00 to 05:59:59), morning (06:00:00 to 11:59:59), afternoon (12:00:00 to 17:59:59), and evening (18:00:00 to 23:59:59). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#assign a time period label to each post based on when it was made\ntime_of_day <- TwitterUse2 %>%  \n   mutate(TimePeriod = format(Time, format=\"%H:%M:%S\")) %>%\n  mutate(TimePeriod = replace(TimePeriod, TimePeriod >= \"00:00:00\" & TimePeriod < \"05:59:59\", \"overnight\")) %>%\n  mutate(TimePeriod = replace(TimePeriod, TimePeriod >= \"06:00:00\" & TimePeriod < \"11:59:59\", \"morning\")) %>%\n  mutate(TimePeriod = replace(TimePeriod, TimePeriod >= \"12:00:00\" & TimePeriod < \"17:59:59\", \"afternoon\")) %>%\n mutate(TimePeriod = replace(TimePeriod, TimePeriod >= \"18:00:00\" & TimePeriod < \"23:59:59\", \"evening\")) %>%\n  select(Author, Date, TimePeriod, Tweet)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., TimePeriod = format(Time, format = \"%H:%M:%S\")): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\ntime_of_day\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'time_of_day' not found\n```\n:::\n:::\n\nCan I pivot this so that I have a count of how many times each account posted in each time frame?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntime_of_day_by_college <- time_of_day %>%\ngroup_by(Author, TimePeriod) %>%\n  summarize(Count=n()) %>%\n  pivot_wider(names_from = TimePeriod, values_from = Count)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in group_by(., Author, TimePeriod): object 'time_of_day' not found\n```\n:::\n\n```{.r .cell-code}\ntime_of_day_by_college[is.na(time_of_day_by_college)] <- 0 \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in time_of_day_by_college[is.na(time_of_day_by_college)] <- 0: object 'time_of_day_by_college' not found\n```\n:::\n\n```{.r .cell-code}\ntime_of_day_by_college\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'time_of_day_by_college' not found\n```\n:::\n:::\n\n\n### Number of posts during each time frame\n\nWith this information, we can now do a broad summary of posts made during each time frame by all of the colleges in the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#number of posts made during each time period\ntime_of_day_count <- time_of_day %>%\ncount(TimePeriod, sort = TRUE,\n        ) %>%\n  rename(\"TimeOfDay\" = \"n\") %>%\n  mutate(TimeOfDayPerc = (TimeOfDay/sum(TimeOfDay)*100))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in count(., TimePeriod, sort = TRUE, ): object 'time_of_day' not found\n```\n:::\n\n```{.r .cell-code}\ntime_of_day_count\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'time_of_day_count' not found\n```\n:::\n:::\n\nA relatively equal proportion of posts are made during the evening (46%) and afternoon (40%), with a small portion of posts made overnight (12%).\n\nI am somewhat surprised by the very small proportion of morning posts, which is making me believe that the timestamps in the dataset (i) do not reflect local time when the post was made; (ii) were also likely given in UTC and not in one of the more common time zones in the US. Given this, I will likely not dive too deeply into any exploration of the impact that time of day has on engagement metrics. \n\n## Descriptive statistics for the response to posts made by the college accounts\n\nMaking posts is certainly an important part of having a social media presence, but how your audience responds to those posts is crucial data that helps to guide social media strategy. Shouting into a vacuum is both inefficient and poor strategy; if no one is consuming and engaging with your content, why invest in creating it to begin with?\n\nWhile there are several metrics that relate to post engagement – including likes, retweets, and replies by one’s Twitter audience – the metric I want to focus on for this analysis is reach. Reach is an estimate of the number of people that have actually seen/read a given post, and the reach listed in this dataset has been calculated using Brandwatch’s proprietary algorithm.\n\n### Average Reach by School\n\nThese are the high level statistics for key metrics overall across the entire college dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(TwitterUse2[c(\"Impressions\", \"Reach\", \"TWLikes\", \"TWRetweets\", \"TWReply\")])\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(TwitterUse2[c(\"Impressions\", \"Reach\", \"TWLikes\", \"TWRetweets\", : object 'TwitterUse2' not found\n```\n:::\n:::\n\nGiven the large difference between the the mean reach (21,024) and the max/min (1,573,085 and 2,882 respectively) this would suggest that there are outliers within the dataset that potentially skew overall results. This trend is similarly seen in the other four metrics as well. \n\nWhile there is a high degree of variability between the minimum and maximum for each major metric, the IQR is more consistent. \n\nNotably, reach seems to be far more consistent across the flagship college Twitter posts when compared to impressions.\n\nImpressions: Median = 141,784, IQR = 103,831\nReach: Median = 19,519, IQR = 7,697\n\nThis gives a quartile based coefficient of variation of 0.73 for impressions, but only 0.39 for reach.\n\nThis would seem to suggest that while some accounts have a greater opportunity for their posts to be seen (ie. impressions), that does not necessarily translate into more people actually reading any given post (ie. reach).\n\n### Summary statistics by college\n\nNext, I want to find the high level summary statistics (max, min, mean, median) for the posts that were made by each college. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Engagement summary statistics by college\neng_met_by_college <- TwitterUse2 %>%\ngroup_by(Author) %>%\n  summarize(\n    Impressions_Max = max(Impressions, na.rm = TRUE), \n    Impressions_Min = min(Impressions, na.rm = TRUE),\nImpressions_Median = median(Impressions, na.rm = TRUE),\nImpressions_Mean = mean(Impressions,na.rm = TRUE),\n Reach_Max = max(Reach, na.rm = TRUE), \n    Reach_Min = min(Reach, na.rm = TRUE),\nReach_Median = median(Reach, na.rm = TRUE),\nReach_Mean = mean(Reach,na.rm = TRUE),\nTWLikes_Max = max(TWLikes, na.rm = TRUE), \n    TWLikes_Min = min(TWLikes, na.rm = TRUE),\nTWLikes_Median = median(TWLikes, na.rm = TRUE),\nTWLikes_Mean = mean(TWLikes,na.rm = TRUE),\nTWRT_Max = max(TWRetweets, na.rm = TRUE), \n    TWRT_Min = min(TWRetweets, na.rm = TRUE),\nTWRT_Median = median(TWRetweets, na.rm = TRUE),\nTWRT_Mean = mean(TWRetweets,na.rm = TRUE),\nTWReply_Max = max(TWReply, na.rm = TRUE), \n    TWReply_Min = min(TWReply, na.rm = TRUE),\nTWReply_Median = median(TWReply, na.rm = TRUE),\nTWReply_Mean = mean(TWReply,na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in group_by(., Author): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\neng_met_by_college\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'eng_met_by_college' not found\n```\n:::\n:::\n\n### Relationship between reach and number of followers \nThe key metric that I'm most interested in is reach, as it is more of a reflection of how many people actually saw a post (as opposed to impressions, which shows the theoretical potential number of people who could have seen a post). \n\nWhat I'd like to layer onto reach is the number of followers that each account has in order to examine the relationship between reach and number of followers. \n\nThe number of followers any Twitter account has can and does vary day-by-day. For simplicity's sake, I am going to use the follower count for the day in November when they had the greatest number of followers to do my subsequent analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Number of followers for each college\nfollowers_by_college <- TwitterUse2 %>%\ngroup_by(Author) %>%\n  summarize(\n    Followers = max(TWFollowers, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in group_by(., Author): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\nfollowers_by_college\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'followers_by_college' not found\n```\n:::\n:::\n\nI can now also pull the summary statistics comparing the number of followers at each flagship institution.\n\n::: {.cell}\n\n```{.r .cell-code}\n#summary statistics for followers by college\nsummary(followers_by_college)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(followers_by_college): object 'followers_by_college' not found\n```\n:::\n:::\n\n\nThese statistics support the assertion that the number of followers that each account has differs greatly - there is a difference of 376,872 followers between the smallest account (University of Wyoming) and the largest (Ohio State). At 137,286, the IQR is also reflective of a great degree of variability in followers by account. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#pull only data for mean on each key metric for each college\nmean_data <- select(eng_met_by_college, \n                      Author, Impressions_Mean, Reach_Mean, TWLikes_Mean,TWRT_Mean, TWReply_Mean)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(eng_met_by_college, Author, Impressions_Mean, Reach_Mean, : object 'eng_met_by_college' not found\n```\n:::\n\n```{.r .cell-code}\n#merge followers_by_college and mean_data\nmerged_college <-  merge(followers_by_college, mean_data, by=\"Author\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in merge(followers_by_college, mean_data, by = \"Author\"): object 'followers_by_college' not found\n```\n:::\n\n```{.r .cell-code}\n#add posts by college as a data point to what I created above\nmerged_college2 <- merge(by_college, merged_college, by=\"Author\") %>%\n  select(Author, Total_Posts, Followers, Impressions_Mean, Reach_Mean, TWLikes_Mean, TWRT_Mean, TWReply_Mean)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in merge(by_college, merged_college, by = \"Author\"): object 'by_college' not found\n```\n:::\n\n```{.r .cell-code}\nmerged_college2\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'merged_college2' not found\n```\n:::\n:::\n\n\n### Compare followers and average reach by college\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#divide mean key metrics by number of followers\nmerged_college2$ImpPerFollower <- merged_college2[,4]/merged_college2[,3]\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'merged_college2' not found\n```\n:::\n\n```{.r .cell-code}\nmerged_college2$ReachPerFollower <- merged_college2[,5]/merged_college2[,3]\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'merged_college2' not found\n```\n:::\n\n```{.r .cell-code}\nmerged_college2\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'merged_college2' not found\n```\n:::\n:::\n\n### Adding in enrollment data\n\nThe Carnegie Foundation for the Advancement of Teaching and the American Council on Education collaborate to provide the Carnegie Classifications. These classifications provide data related to every institution of higher education in the US. Read in data from Carnegie. \n\n::: {.cell}\n\n```{.r .cell-code}\n#import Author > School Name data\nTWAuthor2School <- read_csv(\"posts/_data/Author_SchoolName.csv\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: 'posts/_data/Author_SchoolName.csv' does not exist in current working directory ('C:/Users/Darron Bunt/OneDrive - Ascendium Education Group, Inc/Desktop/601_Fall_2022/posts').\n```\n:::\n\n```{.r .cell-code}\n#import enrollment data from CCIHE \nEnrollmentData <- read_csv(\"posts/_data/CCIHE2021PublicData.csv\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: 'posts/_data/CCIHE2021PublicData.csv' does not exist in current working directory ('C:/Users/Darron Bunt/OneDrive - Ascendium Education Group, Inc/Desktop/601_Fall_2022/posts').\n```\n:::\n\n```{.r .cell-code}\n#combine author > school and merged_college2\ntwitter_enrollment <- merged_college2 %>%\n  left_join(TWAuthor2School, by = \"Author\") %>%\n left_join(EnrollmentData, by = \"SchoolName\") %>%\n  \n  select(Author, SchoolName, F20Enrollment, Followers, Total_Posts, Reach_Mean, SizeSetting) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in left_join(., TWAuthor2School, by = \"Author\"): object 'merged_college2' not found\n```\n:::\n\n```{.r .cell-code}\ntwitter_enrollment$SizeSetting <- str_replace_all(twitter_enrollment$SizeSetting, c(\"Four-year, large, primarily residential\" =\"LargePriRez\", \"Four-year, large, highly residential\" = \"LargeHighRez\", \"Four-year, large, primarily nonresidential\" = \"LargeNonRez\", \"Four-year, medium, primarily nonresidential\" = \"MedNonRez\", \"Four-year, medium, primarily nonresidential\" = \"MedPriRez\", \"Four-year, small, highly residential\" = \"SmallHighRez\", \"Four-year, medium, primarily residential\" = \"MedPriRez\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in stri_replace_all_regex(string, pattern, fix_replacement(replacement), : object 'twitter_enrollment' not found\n```\n:::\n\n```{.r .cell-code}\ntwitter_enrollment\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'twitter_enrollment' not found\n```\n:::\n:::\n\n### Comparing followers to enrollment\n\n::: {.cell}\n\n```{.r .cell-code}\ntwitter_enrollment$TWFolEnr <-  twitter_enrollment$Followers/twitter_enrollment$F20Enrollment\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'twitter_enrollment' not found\n```\n:::\n\n```{.r .cell-code}\ntwitter_enrollment$TWReachEnr <-  twitter_enrollment$Reach/twitter_enrollment$F20Enrollment\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'twitter_enrollment' not found\n```\n:::\n\n```{.r .cell-code}\ntwitter_enrollment_prop <- twitter_enrollment %>%\n  select(SchoolName, TWFolEnr, TWReachEnr)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(., SchoolName, TWFolEnr, TWReachEnr): object 'twitter_enrollment' not found\n```\n:::\n\n```{.r .cell-code}\ntwitter_enrollment_prop\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'twitter_enrollment_prop' not found\n```\n:::\n:::\n\n\n\n## Dissecting posts made by the Twitter authors\n\n### Characters per post\n\n::: {.cell}\n\n```{.r .cell-code}\n#count the number of characters in each Twitter post\nTwitterUse2$TweetCharCount = str_length(TwitterUse2$Tweet)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in stri_length(string): object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\nTwitterUse2 %>%\n  select(Author, TweetCharCount, Tweet)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(., Author, TweetCharCount, Tweet): object 'TwitterUse2' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#number of posts from November that were about athletics\nDissectPosts <- TwitterUse2 %>%\n  select(Author, TWFollowers, Tweet, EngType, TweetCharCount, Reach, TWLikes, TWRetweets, TWReply)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(., Author, TWFollowers, Tweet, EngType, TweetCharCount, : object 'TwitterUse2' not found\n```\n:::\n\n```{.r .cell-code}\nDissectPostsAthletics <- DissectPosts %>%\n  filter(str_detect(Tweet, \"FB|(?i)football|basketball|MBB|WBB|athletics|NCAA\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in filter(., str_detect(Tweet, \"FB|(?i)football|basketball|MBB|WBB|athletics|NCAA\")): object 'DissectPosts' not found\n```\n:::\n\n```{.r .cell-code}\n  DissectPostsAthletics\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'DissectPostsAthletics' not found\n```\n:::\n:::\n\n\n### Most common words used in tweets\n\n::: {.cell}\n\n```{.r .cell-code}\n#Create a vector containing only the text\nTweetText <- DissectPosts$Tweet\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'DissectPosts' not found\n```\n:::\n\n```{.r .cell-code}\n# Create a corpus  \nTweetCorpus <- Corpus(VectorSource(TweetText))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in SimpleSource(length = length(x), content = x, class = \"VectorSource\"): object 'TweetText' not found\n```\n:::\n\n```{.r .cell-code}\nTweetCorpus <- TweetCorpus %>%\n  tm_map(removeNumbers) %>%\n  tm_map(removePunctuation) %>%\n  tm_map(stripWhitespace)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tm_map(., removeNumbers): object 'TweetCorpus' not found\n```\n:::\n\n```{.r .cell-code}\nTweetCorpus <- tm_map(TweetCorpus, content_transformer(tolower))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tm_map(TweetCorpus, content_transformer(tolower)): object 'TweetCorpus' not found\n```\n:::\n\n```{.r .cell-code}\nTweetCorpus <- tm_map(TweetCorpus, removeWords, stopwords(\"english\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tm_map(TweetCorpus, removeWords, stopwords(\"english\")): object 'TweetCorpus' not found\n```\n:::\n\n```{.r .cell-code}\ndtm <- TermDocumentMatrix(TweetCorpus) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in TermDocumentMatrix(TweetCorpus): object 'TweetCorpus' not found\n```\n:::\n\n```{.r .cell-code}\nmatrix <- as.matrix(dtm) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in as.matrix(dtm): object 'dtm' not found\n```\n:::\n\n```{.r .cell-code}\nwords <- sort(rowSums(matrix),decreasing=TRUE) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in rowSums(matrix): 'x' must be an array of at least two dimensions\n```\n:::\n\n```{.r .cell-code}\ndf <- data.frame(word = names(words),freq=words)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in as.data.frame.default(x[[i]], optional = TRUE): cannot coerce class '\"function\"' to a data.frame\n```\n:::\n\n```{.r .cell-code}\nwordcloud(words = df$word, freq = df$freq, min.freq = 100,           max.words=50, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(4, \"Dark2\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in df$freq: object of type 'closure' is not subsettable\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}