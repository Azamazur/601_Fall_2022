---
title: "601 Final Project"
author: "Jerin Jacob"
editor: visual
description: "A study on the crime data of Massachusetts state"
output: distill::distill_article
date: "08/22/2022"
format:
  html:
    toc: true
    code-fold: true
    code-copy: true
    code-tools: true
categories:
  _final_project_601
---

```{r}
#| label: setup
#| warning: false
#| message: false

library(tidyverse)
library(readr)
library(stringr)
library(dplyr)
library(hrbrthemes)
library(ggplot2)
library(tidyr)
library(plotly)


knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Introduction

There are two main types of safety concerns for any living species on earth. One is natural calamities which are obviously uncontrollable, and the second is man-made. The man-made safety related problems can be reduced or controlled if we study it properly and take actions accordingly. Among the man- made safety issues, crimes are always on the top of the list. The study of crime data will give us insights on how to not be a victim, by choosing a place that is less prone to a crime activities. So I decided to take the crime dataset of Massachusetts state and study on it to see if a person chooses to be in a particular location in a county at a specific time of the day, whether it will be safe or not. I am trying to compare the numbers of different counties in the state.

## Data

This is a study on crime data of Massachusetts states. The dataset is a county based number of crimes at a location at a specific time of the day. The data is been taken from the public website of police department. Eventhough the data can be downloaded for the past years, I decided to take the data for 2021 as it is the most recent data. The data from police department had only the number of crimes at a location at a time of the day. If we take just the number of crime as such without considering other factors like the population or population density of the county, the analysis will be incomplete. So as an initial study, I decided to take the county-wise population data from the census 2020 and do the study on crime data as a function relative to the population of the county of occurance.

### Reading the Data:

As there are 14 counties in Massachusetts, my data contains 14 separate county files to be read along with the population data of Massachusetts counties.

#### Reading population Data

```{r}
ma_population <- read_csv('_data/601_final_project_jerin_jacob/MA_population.csv', col_names = c("Number", "County", "Population"))
ma_population$County <- word(ma_population$County, 1)
ma_population <- ma_population[ -c(1) ]
ma_population
```

```{r}
filepath <- "_data/601_final_project_jerin_jacob/"
csv_file_names <- list.files(path = filepath, pattern = "_2021*")
#csv_file_names
```

```{r}
read_crimes<-function(file_name){
  x<-unlist(str_split(file_name, pattern="[[:punct:]]", n=3))
  read_csv(paste0(filepath, file_name),
           skip = 8, 
           col_names = c("Location","6-9pm","9-12pm","12-3am","3-6am","6-9am","9-12noon","12-3pm","3-6pm"))%>%
             mutate(County = x[1],
                    Year = x[2])
}
counties<-
  purrr::map_dfr(csv_file_names, read_crimes) %>%
  select(`Location`, `12-3am`, `3-6am`,  `6-9am`, `9-12noon`, `12-3pm`, `3-6pm`, `6-9pm`, `9-12pm`, `County`, `Year`)
counties
#dim(counties)


```

##Number of crimes per 100,000 residents

```{r}

fig <- plot_ly(
  type = "indicator",
  mode = "gauge+number+delta",
  value = 3211.166	,
  title = list(text = "Crime Rate", font = list(size = 20)),
  delta = list(reference = 2350, increasing = list(color = "RebeccaPurple")),
  gauge = list(
    axis = list(range = list(NULL, 8000), tickwidth = 1, tickcolor = "darkblue"),
    bar = list(color = "darkblue"),
    bgcolor = "yellow",
    borderwidth = 2,
    bordercolor = "gray",
    steps = list(
      list(range = c(0, 2350), color = "green"),
      list(range = c(2350, 4000), color = "royalblue"), 
      list(range = c(4000, 6000), color = "orange"),
      list(range = c(6000, 8000), color = "red")),
    threshold = list(
      line = list(color = "black", width = 4),
      thickness = 0.75,
      value = 7000))) 
fig <- fig %>%
  layout(
    margin = list(l=20,r=30),
    paper_bgcolor = "lavender",
    font = list(color = "darkblue", family = "Arial"))

fig



``
```

```{r}
vals <- county_cr
gauge_plot <- function(vals, breaks=c(0,2000,6000,8000), ncol= NULL) {
    require(ggplot2)
    require(dplyr)
    require(tidyr)
    
    if (!is.data.frame(vals)) stop("Vals must be a dataframe")
    if (!dim(vals)[2]==2) stop("Vals must have two columns")
    if (!is.numeric(vals$Crime_rate)) stop("Dataframe variable pos must be numeric")
    
    
    # function to generate polygons
    get_poly <- function(a,b,r1=0.5,r2=1.0) {
        th.start <- pi*(1-a/100)
        th.end <- pi*(1-b/100)
        th <- seq(th.start,th.end,length=100)
        x <- c(r1*cos(th),rev(r2*cos(th)))
        y <- c(r1*sin(th),rev(r2*sin(th)))
        df <- data.frame(x,y)
        return(df)
    }
    
    
    # create the segments based on the breaks
    segments <- list()
    seg_names <- tibble(x = c("a", "c", "e"), y = c("b", "d" ,"f"))
    
    for(n in 1:3){
        i <-breaks[n]
        j <-breaks[n+1]
        df <- get_poly(i, j)       
        names(df) <- seg_names[n,]
        segments$df[[n]] <- df
    }

    dfs <- bind_cols(segments)

    # create set of segments for each metric 
    pnt <- tibble()
    for (name in vals$County){
        pnt[1:nrow(dfs), name] <- name
    }
    
    dfp <- dfs %>% 
        cbind(pnt) %>% 
        pivot_longer(-c(a:f), names_to = "County") %>% 
        select(-value)
    
    # generate the needles
    needles <- list()
    for(p in 1:nrow(vals)){
        i <-vals$Crime_rate[p] - 1
        j <-vals$Crime_rate[p] + 1
        r1 <- 0.2
        df <- get_poly(i, j, r1)  
        df$County <- vals$County[p]
        needles$df[[p]] <- df
    }
    
    dfn <- bind_rows(needles)
    
    
    # graph
    ggplot()+
        geom_polygon(data=dfp, aes(a,b), fill="red")+
        geom_polygon(data=dfp, aes(c,d), fill="gold")+
        geom_polygon(data=dfp, aes(e,f), fill="forestgreen")+
        geom_polygon(data=dfn, aes(x,y))+
        geom_text(data=as.data.frame(breaks), size=3, fontface="bold", vjust=0,
                  aes(x=1.05*cos(pi*(1-breaks/100)),y=1.05*sin(pi*(1-breaks/100)),label=breaks))+
        geom_text(data=vals, aes(x=0,y=0), label=paste0(vals$Crime_rate,"%"), vjust=0, size=4, fontface="bold")+
        coord_fixed()+
        theme_bw()+
        theme(axis.text=element_blank(),
              axis.title=element_blank(),
              axis.ticks=element_blank(),
              panel.grid=element_blank(),
              panel.border=element_blank()) +
        facet_wrap(~metric, strip.position = "bottom", ncol = ncol) +
        labs(title = "Multiple Gauge Plots w/ Facet Wrap")
}
gauge_plot(county_crime_rate)

```

```{r}
County_crime_total <- filter(counties, Location == "All Location Types")
#head(County_crime_total)
#head(ma_population)

```

```{r}

County_crime_total %>%
  left_join(ma_population,by= "County")%>%
  mutate(across(c(2:9),
           .fns = ~./(Population/100000)))%>%
  pivot_longer(cols = (ends_with("am") | ends_with("pm")) | ends_with("noon"), names_to = "Time", values_to = "Crime_Rate") %>%
  group_by(Time, County) %>%
 
  ggplot(aes(x = County, y = Crime_Rate, fill = Time)) + 
    geom_bar(stat = "identity", position = position_dodge(0.9)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

```{r}
County_crime_total %>%
  left_join(ma_population,by= "County")%>%
  mutate(across(c(2:9),
           .fns = ~./(Population/100000)))%>%
  pivot_longer(cols = (ends_with("am") | ends_with("pm")) | ends_with("noon"), names_to = "Time", values_to = "Crime_Rate") %>%
  group_by(Time, County) %>%
  
  ggplot( aes(x=Time, y=Crime_Rate, group=County, color=County)) +
    geom_line()




```

### Understanding the Data:

The population data is a clean data that has 14 rows of each county and the population.

The crime data contains 54 rows and 11 columns for each county files. 54 rows are different location types in the county categorised as where any crime can possibly occur.

### Sanity Check:

In the dataset, there is a row for 'All Location Types'. I expected that to be same as the sum of all other Locations but it was not. This could be due to either data entry errors or overlapping/duplication of data in Locations with similar names. I could find 6 such Locations that duplicated. 'Commercial', 'Educational Facility', 'Government/Public Building and other', 'Road/Parking/Camps', 'Field/Woods/Waterways/Camps' and 'Construction/Industrial/Farm'. Those 6 Location types are just grouping of two or more other Location Types.

```{r}
first_county <- counties %>%
  slice(1:54)
first_county

first_county2 <- first_county %>%
  slice(2:54)
mapply(sum,first_county2[,c(2:9)], na.rm= TRUE)

```

So I checked by droping those overlapping/duplicated locations for the Barnstable County and again rechecked. Now the sum of the locations is same as that of 'All Location Types'.

```{r}
dfRemain <- first_county[-c(3, 22,27,42,47,38), ]


dfRemain

all_location <- dfRemain[c(1), ]
all_location %>%
  select(2:9)

df <-  dfRemain[-c(1), ]
mapply(sum,df[,c(2:9)], na.rm= TRUE)

```

```{r}
new_county_data<-subset(counties, Location != 'Commercial' & Location !='Educational Facility' & Location != 'Government/Public Building and other' & Location != 'Road/Parking/Camps' & Location != 'Field/Woods/Waterways/Camps' & Location != 'Construction/Industrial/Farm' & Location != 'All Location Types')
new_county_data
```

```{r}
dim(counties)
```

```{r}

```

#### Joining the crime data for 2021 with the population dataset of Massachusetts

```{r}
ma_crime_2021 <- new_county_data %>% left_join(ma_population,by="County")
```

The number of crimes per 1000 people in the county can be a good way to start with the analysis. So I scaled down the population data to per 1000.

```{r}
crime_per_population <- ma_crime_2021 %>%  
    mutate(across(c(2:9),
           .fns = ~./(Population/1000)))
crime_per_population
```

```{r}
crime_per_population <- pivot_longer(crime_per_population, `6-9pm`:`3-6pm`, names_to = "Time_of_day", values_to = "Crime_rate")

```

```{r}
df <- crime_per_population[ -c(3,4) ]
head(df)

```

```{r}
summary(df)
```

According to the data, the safest place in Massachusetts is an Air/Bus/Train Terminal in Middlesex at 12-3 am. Apparently, residences of Hampden between 3-6 pm turns out to be the most unsafe place or where most crimes happen.

```{r}
df[which.max(df$Crime_rate),]
df[which.min(df$Crime_rate),]

```

Checking whether all locations in Hampden have high crime rates and if Middlesex is safe in all locations.

```{r}
df_middlesex <- df %>%
  filter(County == "Middlesex")

ggplot(df_middlesex, aes(x=Time_of_day, y=Crime_rate)) +
  geom_segment( aes(x=Time_of_day, xend=Time_of_day, y=0, yend=Crime_rate)) +
  geom_point( size=5, color="red", fill=alpha("orange", 0.3), alpha=0.7, shape=21, stroke=2) 

df_hampden <- df %>%
  filter(County == "Hampden")

ggplot(df_hampden, aes(x=Time_of_day, y=Crime_rate)) +
  geom_segment( aes(x=Time_of_day, xend=Time_of_day, y=0, yend=Crime_rate)) +
  geom_point( size=5, color="red", fill=alpha("orange", 0.3), alpha=0.7, shape=21, stroke=2)

```

### Comparing the crime rates in different counties.

```{r}
df %>% ggplot(aes(Time_of_day, Crime_rate, color=County)) + geom_point()

```

```{r}
ggplot(df, aes(fill=County, y=Crime_rate, x=Time_of_day)) + 
    geom_bar(position="stack", stat="identity")
```

## Reflection

The data should be studied in depth to compare and find which time/location is safer. With the limited knowledge on R programming, I couldn't do all the analysis that I wanted to do in the time limit. I am planning to continue working on this project as my R knowledge gets stronger.

## Conclusion

The crime data is an interesting dataset to be studied and with the minimal resource and knowledge I have, the analysis is incomplete.

## Bibliography

#### Source of data: https://masscrime.chs.state.ma.us/public/View/dispview.aspx

#### Programming Language: R

#### Course book : R for Data Science by Hadley Wickham & Garrett Grolemund
